{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import requests\n",
    "import sys\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open('C://Users//rladh//Downloads//BOAZ//BOAZ adv//프로젝트//0602.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################URL 긁어오기\n",
    "url = 'http://search.naver.com/search.naver' # 기본 형태 url\n",
    "hrd = {'User-Agent':'Mozilla/5.0' , 'referer' : 'http://naver.com'} \n",
    "post_dict = OrderedDict() #중복 여부를 체크하기 위한 딕셔너리 변수\n",
    "cnt = 1 #갯수를 세기위한 변수\n",
    "\n",
    "for page in count(1,1):\n",
    "    param = {\n",
    "    'where' : 'post', # 블로그 탭\n",
    "    'query' : '강남맛집',# 검색어\n",
    "    'date_from':'20180601', # 시작날짜\n",
    "    'date_to':'20180607', # 종료날짜 : 2주만에 10000개....ㅎ\n",
    "    'date_option':'8', # (0,2,3,4,6,7,8) = (전체,1일,1주,1달,6개월,1년,사용자)\n",
    "    'start': (page - 1) * 10 + 1\n",
    "    }\n",
    "    response = requests.get(url,params=param,headers=hrd)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    area = soup.find(\"div\", {\"class\": \"blog section _blogBase\"}).find_all(\"a\", {\"class\":\"url\"}) \n",
    "     # div 영역의 class값을 추리고, a태그 중에서 url인 영역 출력\n",
    "\n",
    "    if cnt <1000 :\n",
    "        for tag in area:\n",
    "            url1=tag.get('href')\n",
    "            print(\"{:} {:}\".format(cnt,url1))\n",
    "            post_dict[tag['href']] = tag.text # url값과 태그내용으로 post_dict 딕셔너리에 저장\n",
    "            cnt +=1\n",
    "            \n",
    "    else : \n",
    "        print(\"마지막 페이지 마지막블로그 입니다 링크추출을 종료합니다\")\n",
    "        sys.exit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################URL 가공하기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_final_url():\n",
    "    try:\n",
    "        url_1=\"https://cradmaser.blog.me/221242210403\"                     # 크롤링해서 얻어낸 1\n",
    "        html_result = requests.get(url_1)                                  # html 소스코드 받아오기\n",
    "        soup_temp = BeautifulSoup(html_result.text,'html.parser')          # 소스코드 파싱\n",
    "        area_temp = soup_temp.find(id='screenFrame')                       # id가 \"screenFrame\"인 frame 태그 찾기\n",
    "        url_2 = area_temp.get('src')                                       # url_2에 src가 가진 URL 넣기\n",
    "                                                                           # 즉 url_2 = 2\n",
    "        \n",
    "        #예외가 발생한 경우는 id가 'screenFrame'인 태그를 못찾았을 때이며, \n",
    "        #이는 처음 url이 2라는 의미이므로 바로 다음단계부터 실행\n",
    "        except:\n",
    "            try:\n",
    "                area_temp = soup_temp.find(id='mainFrame')\n",
    "                url_3     = area_temp.get('src')                           # url_3 src가 가진 부분URL 넣기\n",
    "                url_4 = \"https://blog.naver.com\" + url_3                   # 4 = \"https://blog.naver.com\" + 3\n",
    "            \n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        #예외가 아닌 경우 얻어 2를 가지고 다음 단계 실행\n",
    "        try:\n",
    "            html_result = requests.get(url_2)                                  # 2를 이용하여 html 소스코드 받아오기\n",
    "            soup_temp = BeautifulSoup(html_result.text,'html.parser')          # 소스코드 파싱\n",
    "            area_temp = soup_temp.find(id='screenFrame')                       # id가 \"mainFrame\"인 frame 태그 찾기\n",
    "            url_3 = area_temp.get('src')                                       # url_3 src가 가진 부분URL 넣기\n",
    "            url_4 = \"https://blog.naver.com\" + url_3                           # 4 = \"https://blog.naver.com\" + 3\n",
    "            return url_4\n",
    "        except url_4\n",
    "            print(\"error\")\n",
    "            return None                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################추출한 URL 제목과 본문추출 및 전처리(불필요한 공백 및 개행문자 제거)\n",
    "\n",
    "def get_text(final_url):\n",
    "\ttry :\n",
    "\t\t##제목과 본문부분 추출\n",
    "\t\tres = req.urlopen(final_url)\n",
    "\t\tsoup = BeautifulSoup(res, 'html.parser')\n",
    "\t\ttemp = soup.select(\"#se_textarea\")\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t##title 추출\n",
    "\t\ttitle = soup.findAll(\"span\", {\"class\":\"pcol1 itemSubjectBoldfont\"})\n",
    "\t\tfor a in title:\n",
    "\t\t\ttext = no_space(a.get_text())\n",
    "\t\t\tprint (text)\n",
    "\t\t\t\n",
    "\t\t##본문 추출\n",
    "\t\ttemp = soup.findAll(\"div\", {\"id\":\"postViewArea\"})\n",
    "\t\tfor a in temp:\n",
    "\t\t\ttext = no_space(a.get_text())\n",
    "\t\t\tprint(text)\n",
    "\n",
    "\texcept:\n",
    "\t\tprint(\"크롤링실패\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def no_space(text):\n",
    "\ttext1 = re.sub('&nbsp; | &nbsp;| \\n|\\t|\\r', '', text)\n",
    "\ttext2 = re.sub('\\n\\n', '', text1)\n",
    "\treturn text2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
